[DEFAULT]
# Add debug logging, given all the problems we are seeing
debug = True
# make direct deploy faster, transfer sparse qcow2 images
force_raw_images = False
# Avoid some rpc timeouts
rpc_response_timeout = 120

# Seeing too many inflight requests to the DB
# so we reduce the size of the pool
[database]
max_overflow = 18
# Usually this is 5
max_pool_size = 2
# Usually this is 3600
connection_recycle_time = 60

# Usually this is 50, reduce to stop DB connection timeouts
# and instead just make eventlet threads wait a bit longer
max_overflow = 5
# Usually this is 5
max_pool_size = 5
# Usually this is 3600, reduce this to make it less likely
# to get a connection out the pool that has already timed out
connection_recycle_time = 1800
# By default this is 30 seconds, but as we reduce
# the pool overflow, some people will need to wait longer
pool_timeout = 60

[pxe]
# Make it less likely to loose image out of the cache
# as slurm rolls through doing updates
image_cache_size = 81920
image_cache_ttl = 100800

[console]
socat_address = {% raw %}{{ api_interface_address }}{% endraw %}

[conductor]
automated_clean=true

# We have busy conductors failing to heartbeat
# causing a false conductor takeover.
# default is 10 secs
heartbeat_interval = 30
# default is 60 seconds
heartbeat_timeout = 360

# Normally this is 100. We see eventlet threads
# not making much progress, to for saftey reduce
# this by half, should leave work on rabbit queue
workers_pool_size = 50
# Normally this is 8, keep it same
periodic_max_workers = 8

# Reduce background CPU load, by stopping power sync
sync_power_state_interval = 0
power_failure_recovery_interval = 0
# stop checking for orphanen allocations for now
check_allocations_interval = 0

# wait much longer before provision timeout check
# to reduce background load, the default is 60 seconds
check_provision_state_interval = 120
check_rescue_state_interval = 120

[agent]
# Use iPXE server for direct deploy source
image_download_source = http
# Reduce load by only collecting logs on failure
deploy_logs_collect = on_failure

[deploy]
shred_random_overwrite_iterations = 0
shred_final_overwrite_with_zeros = false
continue_if_disk_secure_erase_fails = true

[neutron]
# Increase the neutron client timeout to allow for the slow management
# switches.
timeout = 300
request_timeout = 300

[glance]
# Seen some errors talking to glance, add a retry
# but haproxy timeout changes reduce the need for this
num_retries = 1
